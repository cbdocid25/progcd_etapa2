# üõ°Ô∏è Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito com LLM (RAG)

Este projeto integra t√©cnicas de aprendizado de m√°quina e modelos de linguagem (LLMs) com a abordagem RAG (Retrieval-Augmented Generation) para detec√ß√£o e explica√ß√£o de fraudes em cart√µes de cr√©dito.

## üìå Objetivo

Desenvolver uma solu√ß√£o capaz de identificar transa√ß√µes fraudulentas e, ao mesmo tempo, explicar em linguagem natural as decis√µes do modelo, utilizando uma LLM integrada via LangChain e FAISS.

## üìä Dataset

- Fonte: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/code/gpreda/credit-card-fraud-detection-predictive-models)
- Cont√©m 284.807 transa√ß√µes no total, das quais apenas 492 s√£o fraudes (0,17%).
- Todas as vari√°veis (exceto 'Time' e 'Amount') s√£o resultados de PCA para anonimiza√ß√£o.

## üõ†Ô∏è Tecnologias e Ferramentas

- Python 3.10+
- Jupyter Notebook
- Pandas, Scikit-Learn, XGBoost
- SHAP (para interpretabilidade)
- FAISS (para cria√ß√£o de vetores)
- LangChain (para integra√ß√£o com LLM)
- OpenAI API (ou outra LLM compat√≠vel)

## üß† Abordagem

1. Pr√©-processamento do dataset.
2. Treinamento de modelos de detec√ß√£o (baseline).
3. Explicabilidade com SHAP values.
4. Indexa√ß√£o vetorial com FAISS.
5. Integra√ß√£o com LangChain para gera√ß√£o de explica√ß√µes usando LLM.
6. Compara√ß√£o dos modelos com e sem aux√≠lio da LLM.

## üë• Equipe

- Alexandre Teixeira da Silva
- C√©sar Braz de Oliveira
- √çcaro Guimar√£es Canto
- Priscila Leylianne da Silva Gon√ßalves

# Etapa 1.3 ‚Äî Aplicar Pr√©-processamento: Normaliza√ß√£o + PCA

Nesta etapa, realizamos o pr√©-processamento do dataset original de detec√ß√£o de fraudes em transa√ß√µes de cart√£o de cr√©dito, aplicando duas t√©cnicas fundamentais:

---

## Objetivos

- Normalizar as vari√°veis cont√≠nuas do dataset (`Time` e `Amount`)
- Aplicar PCA (An√°lise de Componentes Principais) para reduzir a dimensionalidade das 28 features anonimizadas (`V1` a `V28`)
- Gerar um novo dataset reduzido, facilitando a visualiza√ß√£o, detec√ß√£o de padr√µes e aplica√ß√£o de modelos futuros

---

## T√©cnicas aplicadas

### 1. Normaliza√ß√£o (StandardScaler)
- Utilizamos a t√©cnica de padroniza√ß√£o Z-score (`StandardScaler`) para transformar `Time` e `Amount` em dados com m√©dia 0 e desvio padr√£o 1
- Isso evita que essas colunas interfiram negativamente nos algoritmos baseados em dist√¢ncia ou gradiente

### 2. PCA ‚Äî Principal Component Analysis
- Redu√ß√£o das 28 colunas (`V1` a `V28`) para os 10 principais componentes (`PCA1` a `PCA10`)
- Reten√ß√£o de mais de **80% da vari√¢ncia total** do dataset original
- Aplica√ß√£o com `sklearn.decomposition.PCA(n_components=10)`

---

## Arquivos envolvidos

- **Entrada**: `dataset_simulado.csv` ou `creditcard.csv` (vers√£o original)
- **Sa√≠da 1**: `dataset_normalizado.csv` (com `Time`, `V1`‚Äì`V28`, `Amount`, `Class` normalizados)
- **Sa√≠da 2**: `dataset_com_pca.csv` (com `PCA1` a `PCA10`, `Time`, `Amount`, `Class`)

---

## Por que aplicar PCA?

- Reduz o custo computacional em modelos futuros
- Remove multicolinearidade entre vari√°veis
- Facilita visualiza√ß√µes 2D e clustering
- Preserva o m√°ximo de informa√ß√£o com menos colunas

---

## Como executar esta etapa

```bash
python pre_processamento_pca.py
```

Certifique-se de ter as bibliotecas instaladas:

```bash
pip install pandas scikit-learn
```

---

## Resultado Esperado

- Dataset escalonado
- Dataset reduzido com 10 colunas PCA
- CSVs prontos para serem usados no treinamento de modelos (Etapa 2.1)

---
# Etapa 2.1 ‚Äî Treinar Modelos Supervisionados

Nesta etapa do projeto, realizamos o treinamento de modelos supervisionados utilizando os dados pr√©-processados do dataset de transa√ß√µes financeiras para detec√ß√£o de fraudes.

---

## Objetivo

- Utilizar algoritmos de classifica√ß√£o supervisionada para prever a classe da transa√ß√£o (`0` = leg√≠tima, `1` = fraude)
- Avaliar a performance dos modelos com base em m√©tricas padr√£o
- Salvar os resultados comparativos para futuras an√°lises e visualiza√ß√µes

---

## Arquivo de entrada

- `creditcard.csv` (vers√£o original do Kaggle com `Time`, `V1‚ÄìV28`, `Amount`, `Class`)
- Pr√©-requisito: `Time` e `Amount` devem estar normalizados com `StandardScaler`

---

## Modelos treinados

### 1. Logistic Regression
- Algoritmo linear que usa fun√ß√£o sigmoide para prever a probabilidade de fraude
- Otimizador: `saga`
- Itera√ß√µes: at√© `5000`

### 2. Random Forest
- Conjunto de √°rvores de decis√£o aleat√≥rias com vota√ß√£o
- Robusto e eficaz mesmo com dados desbalanceados
- `n_estimators = 100`

---

## M√©tricas geradas

Para cada modelo, foram calculadas as seguintes m√©tricas:

| M√©trica     | Descri√ß√£o                                           |
|-------------|------------------------------------------------------|
| Accuracy    | Propor√ß√£o de acertos sobre o total                   |
| Precision   | Propor√ß√£o de fraudes corretas entre as previstas     |
| Recall      | Propor√ß√£o de fraudes encontradas entre as reais      |
| F1-Score    | M√©dia harm√¥nica entre Precision e Recall             |
| ROC-AUC     | Capacidade do modelo em distinguir classes           |

---

## Resultado salvo

- Os resultados das m√©tricas foram organizados em um arquivo:
  - `resultados_modelos.csv`

Exemplo (valores ilustrativos):

| Modelo              | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|---------------------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.9992   | 0.76      | 0.65   | 0.70     | 0.95    |
| Random Forest       | 0.9996   | 0.89      | 0.79   | 0.84     | 0.98    |

---

## Execu√ß√£o

```bash
python treinamento_modelos_basicos.py
```

Bibliotecas necess√°rias:

```bash
pip install pandas scikit-learn
```

---

## Sa√≠da

- `resultados_modelos.csv`: comparativo dos dois algoritmos
- Impress√£o dos tempos de execu√ß√£o:
  - In√≠cio
  - Fim
  - Dura√ß√£o total

---
