# Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito com LLM

Este projeto integra t√©cnicas de aprendizado de m√°quina e modelos de linguagem (LLMs) com a abordagem RAG (Retrieval-Augmented Generation) para detec√ß√£o e explica√ß√£o de fraudes em cart√µes de cr√©dito.

## Objetivo

Desenvolver uma solu√ß√£o capaz de identificar transa√ß√µes fraudulentas e, ao mesmo tempo, explicar em linguagem natural as decis√µes do modelo, utilizando uma LLM integrada via LangChain.

## Como Executar o Aplicativo de Intera√ß√£o com LLM

Este projeto permite a intera√ß√£o com um modelo de linguagem (LLM) para an√°lise de fraudes em transa√ß√µes de cart√£o de cr√©dito. Ele foi desenvolvido com o objetivo de tornar a explora√ß√£o de dados mais intuitiva, atrav√©s de perguntas em linguagem natural.

---

## Estrutura Principal

O projeto √© composto por tr√™s arquivos principais:

- `helper.py`: cont√©m fun√ß√µes auxiliares para tratamento de dados e formata√ß√£o de respostas.  
- `engine.py`: orquestra a l√≥gica de consulta, integra√ß√£o com a LLM e formata√ß√£o dos resultados.  
- `main.py`: ponto de entrada da aplica√ß√£o. Ao ser executado, inicia a interface e permite intera√ß√£o com o modelo.

---

## Executando a Aplica√ß√£o

Certifique-se de que todas as depend√™ncias est√£o instaladas (ver se√ß√£o abaixo).
No terminal, execute o seguinte comando:

```bash
python main.py
```

A aplica√ß√£o ser√° iniciada.
Voc√™ poder√° fazer perguntas como:
- "Quantas transa√ß√µes fraudulentas existem no dataset?"
- "Qual foi o maior valor entre as fraudes?"
- "Crie um gr√°fico de dispers√£o entre fraudes e opera√ß√µes leg√≠timas e atribua as cores azul para leg√≠tima e laranja para as fraudes"

O sistema interpretar√° a pergunta e apresentar√° a resposta com base no dataset de fraude de cart√µes de cr√©dito.

## Requisitos

Antes de rodar, instale as depend√™ncias com:
```bash
pip install -r requirements.txt
```

Se estiver utilizando ambiente virtual (recomendado), ative-o antes de executar o comando acima.

---

## Observa√ß√£o
Este projeto utiliza uma arquitetura modular com suporte a agentes LLM, oferecendo uma camada inteligente sobre os dados para facilitar an√°lises sem necessidade de escrever c√≥digo ou queries complexas.


## Dataset

O dataset utilizado neste projeto √© baseado no conjunto de dados original do Kaggle sobre detec√ß√£o de fraudes em cart√µes de cr√©dito. Este arquivo foi **manipulado e enriquecido** com os julgamentos de **tr√™s modelos de aprendizado supervisionado** (Regress√£o Log√≠stica, Random Forest e XGBoost), resultando em colunas adicionais com as predi√ß√µes de cada modelo.

Devido ao seu tamanho final (153.9MB), ele n√£o p√¥de ser hospedado diretamente neste reposit√≥rio GitHub.
Voc√™ pode baix√°-lo atrav√©s do link abaixo:

üîó [Clique aqui para acessar o dataset no Google Drive](https://drive.google.com/drive/folders/1Gp9VLrw08iapNNpInsbsl6o9w46Jb9bT?usp=drive_link)

Ap√≥s o download, adicione o arquivo na seguinte estrutura de diret√≥rio dentro do projeto:

```
nome_do_projeto/
‚îî‚îÄ‚îÄ model/
    ‚îî‚îÄ‚îÄ dataset/
        ‚îî‚îÄ‚îÄ relatorio_treinamento.csv
```

> **Importante:** o caminho acima deve ser seguido exatamente para garantir o funcionamento do sistema, conforme definido na vari√°vel:

```python
DATASET_PATH = "model/dataset/relatorio_treinamento.csv"
```

## Fonte do dataset original:
üîó [Click aqui para acessar o dataset no Kaggle](https://www.kaggle.com/code/gpreda/credit-card-fraud-detection-predictive-models)


## Tecnologias e Ferramentas

- Python 3.10+
- Jupyter Notebook
- Pandas, Scikit-Learn, XGBoost
- SHAP (para interpretabilidade)
- FAISS (para cria√ß√£o de vetores)
- LangChain (para integra√ß√£o com LLM)
- OpenAI API (ou outra LLM compat√≠vel)

## Abordagem

1. Pr√©-processamento do dataset.
2. Treinamento de modelos de detec√ß√£o (baseline).
3. Explicabilidade com SHAP values.
4. Indexa√ß√£o vetorial com FAISS.
5. Integra√ß√£o com LangChain para gera√ß√£o de explica√ß√µes usando LLM.
6. Compara√ß√£o dos modelos com e sem aux√≠lio da LLM.

## Equipe

- Alexandre Teixeira da Silva
- C√©sar Braz de Oliveira
- √çcaro Guimar√£es Canto
- Priscila Leylianne da Silva Gon√ßalves

# Etapa 1.3 ‚Äî Aplicar Pr√©-processamento: Normaliza√ß√£o + PCA

Nesta etapa, realizamos o pr√©-processamento do dataset original de detec√ß√£o de fraudes em transa√ß√µes de cart√£o de cr√©dito, aplicando duas t√©cnicas fundamentais:

---

## Objetivos

- Normalizar as vari√°veis cont√≠nuas do dataset (`Time` e `Amount`)
- Aplicar PCA (An√°lise de Componentes Principais) para reduzir a dimensionalidade das 28 features anonimizadas (`V1` a `V28`)
- Gerar um novo dataset reduzido, facilitando a visualiza√ß√£o, detec√ß√£o de padr√µes e aplica√ß√£o de modelos futuros

---

## T√©cnicas aplicadas

### 1. Normaliza√ß√£o (StandardScaler)
- Utilizamos a t√©cnica de padroniza√ß√£o Z-score (`StandardScaler`) para transformar `Time` e `Amount` em dados com m√©dia 0 e desvio padr√£o 1
- Isso evita que essas colunas interfiram negativamente nos algoritmos baseados em dist√¢ncia ou gradiente

### 2. PCA ‚Äî Principal Component Analysis
- Redu√ß√£o das 28 colunas (`V1` a `V28`) para os 10 principais componentes (`PCA1` a `PCA10`)
- Reten√ß√£o de mais de **80% da vari√¢ncia total** do dataset original
- Aplica√ß√£o com `sklearn.decomposition.PCA(n_components=10)`

---

## Arquivos envolvidos

- **Entrada**: `dataset_simulado.csv` ou `creditcard.csv` (vers√£o original)
- **Sa√≠da 1**: `dataset_normalizado.csv` (com `Time`, `V1`‚Äì`V28`, `Amount`, `Class` normalizados)
- **Sa√≠da 2**: `dataset_com_pca.csv` (com `PCA1` a `PCA10`, `Time`, `Amount`, `Class`)

---

## Por que aplicar PCA?

- Reduz o custo computacional em modelos futuros
- Remove multicolinearidade entre vari√°veis
- Facilita visualiza√ß√µes 2D e clustering
- Preserva o m√°ximo de informa√ß√£o com menos colunas

---

## Como executar esta etapa

```bash
python pre_processamento_pca.py
```

Certifique-se de ter as bibliotecas instaladas:

```bash
pip install pandas scikit-learn
```

---

## Resultado Esperado

- Dataset escalonado
- Dataset reduzido com 10 colunas PCA
- CSVs prontos para serem usados no treinamento de modelos (Etapa 2.1)

---
# Etapa 2.1 ‚Äî Treinar Modelos Supervisionados

Nesta etapa do projeto, realizamos o treinamento de modelos supervisionados utilizando os dados pr√©-processados do dataset de transa√ß√µes financeiras para detec√ß√£o de fraudes.

---

## Objetivo

- Utilizar algoritmos de classifica√ß√£o supervisionada para prever a classe da transa√ß√£o (`0` = leg√≠tima, `1` = fraude)
- Avaliar a performance dos modelos com base em m√©tricas padr√£o
- Salvar os resultados comparativos para futuras an√°lises e visualiza√ß√µes

---

## Arquivo de entrada

- `creditcard.csv` (vers√£o original do Kaggle com `Time`, `V1‚ÄìV28`, `Amount`, `Class`)
- Pr√©-requisito: `Time` e `Amount` devem estar normalizados com `StandardScaler`

---

## Modelos treinados

### 1. Logistic Regression
- Algoritmo linear que usa fun√ß√£o sigmoide para prever a probabilidade de fraude
- Otimizador: `saga`
- Itera√ß√µes: at√© `5000`

### 2. Random Forest
- Conjunto de √°rvores de decis√£o aleat√≥rias com vota√ß√£o
- Robusto e eficaz mesmo com dados desbalanceados
- `n_estimators = 100`

---

## M√©tricas geradas

Para cada modelo, foram calculadas as seguintes m√©tricas:

| M√©trica     | Descri√ß√£o                                           |
|-------------|------------------------------------------------------|
| Accuracy    | Propor√ß√£o de acertos sobre o total                   |
| Precision   | Propor√ß√£o de fraudes corretas entre as previstas     |
| Recall      | Propor√ß√£o de fraudes encontradas entre as reais      |
| F1-Score    | M√©dia harm√¥nica entre Precision e Recall             |
| ROC-AUC     | Capacidade do modelo em distinguir classes           |

---

## Resultado salvo

- Os resultados das m√©tricas foram organizados em um arquivo:
  - `resultados_modelos.csv`

Exemplo (valores ilustrativos):

| Modelo              | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|---------------------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.9992   | 0.76      | 0.65   | 0.70     | 0.95    |
| Random Forest       | 0.9996   | 0.89      | 0.79   | 0.84     | 0.98    |

---

## Execu√ß√£o

```bash
python treinamento_modelos_basicos.py
```

Bibliotecas necess√°rias:

```bash
pip install pandas scikit-learn
```

---

## Sa√≠da

- `resultados_modelos.csv`: comparativo dos dois algoritmos
- Impress√£o dos tempos de execu√ß√£o:
  - In√≠cio
  - Fim
  - Dura√ß√£o total

---
